{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rc7-5tqgHEHQ","executionInfo":{"status":"ok","timestamp":1668179100396,"user_tz":300,"elapsed":17983,"user":{"displayName":"Chuyang Xiao","userId":"02548350807511210968"}},"outputId":"4cf2f59d-357a-493e-92ea-13fffba32871"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Import necessary libraries\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import nltk\n","import pandas as pd\n","import os\n","import re\n","import string \n","\n","from collections import defaultdict\n","from google.colab import drive\n","from glob import glob\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","from skimage import io, transform\n","\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/ENGI 4800/data/df_converted.csv', index_col=False).dropna()[['pii','Section_content','Converted_Section_Content','Authors']]\n","m,n = df.shape\n","df.index = np.arange(m)\n","df.columns = ['pii','Section_content', 'Converted_Section_Content','Authors']\n","\n","df_copy = df.copy()\n","\n","df_splitted = df_copy"],"metadata":{"id":"vhbqBWS9OMi_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["splitted_texts = []\n","sentences_count = []\n","for index, row in df_splitted.iterrows():\n","\n","    # add paragraph sentences count \n","    content = row[2]\n","    \n","    replaced_txt = re.sub(r\"([^A-Z])([.|;]\\s+)\", r\"\\1\\n\", content)\n","    splitted_txt = re.split(r\"\\n\", replaced_txt)\n","    \n","    sentences_count.append(len(splitted_txt)) \n","    splitted_texts.append(splitted_txt)\n","    \n","df_splitted.insert(1,'Sentences_count', sentences_count)\n","df_splitted.insert(2,'Splitted_txt', splitted_texts)\n","df_splitted.drop(df_splitted[df_splitted['Sentences_count'] == 1].index, inplace=True)\n","\n","sentences_all = []\n","\n","for index, row in df_splitted.iterrows():\n","    sentences_all += row[2]\n","df_sentences = pd.DataFrame(sentences_all, columns =['Original_txt'])\n","\n","authorsId_removed = []\n","for index, row in df_sentences.iterrows():\n","    authorsId_removed.append(re.sub('#[\\d]+', '', row[0]))\n","    \n","df_sentences.insert(1,'AuthorsId_removed', authorsId_removed)"],"metadata":{"id":"4VWLfwnZH211"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('punkt', quiet=True)\n","nltk.download(\"stopwords\", quiet=True)\n","stop_words = set(stopwords.words('english'))\n","\n","punctuations = string.punctuation\n","\n","punctuation_stopWord_removed = []\n","\n","for index, row in df_sentences.iterrows():\n","    sentence = row[1]\n","    sentence = sentence.translate(str.maketrans('', '', string.punctuation.replace('#','')))\n","    filtered_sentence = [w for w in word_tokenize(sentence) if not w.lower() in stop_words]\n","    punctuation_stopWord_removed.append(' '.join(filtered_sentence))\n","    \n","df_sentences.insert(2,'punctuation_stopWord_removed', punctuation_stopWord_removed) "],"metadata":{"id":"vVeQArUSMWE7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["porter = PorterStemmer()\n","df_stem = df_sentences.copy()\n","stemed = []\n","\n","for i, row in df_sentences.iterrows():\n","    sentence = df_sentences['punctuation_stopWord_removed'][i].split()\n","    stemed.append(' '.join([porter.stem(word) for word in sentence]))\n","    \n","df_sentences.insert(3,'stemmed', stemed) \n","\n","df_sentences_copy = df_sentences.copy()\n","df_sentences_copy.drop(df_sentences[(df_sentences['stemmed'] == '') ].index, inplace=True)"],"metadata":{"id":"LZ1cLqp0NAoH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_review_edit = df_sentences_copy.loc[(df_sentences_copy.stemmed.str.contains('review',na=False) | \n","                                   df_sentences_copy.stemmed.str.contains('revis',na=False) | \n","                                   df_sentences_copy.stemmed.str.contains('edit',na=False) |\n","                                   df_sentences_copy.stemmed.str.contains('critic',na=False)) &\n","                                   ~(\n","                                       df_sentences_copy.stemmed.str.contains('manuscript',na=False) |\n","                                     df_sentences_copy.stemmed.str.contains('origin',na=False) |\n","                                     df_sentences_copy.stemmed.str.contains('supervis',na=False) |\n","                                     df_sentences_copy.stemmed.str.contains('All',na=False) |\n","                                     df_sentences_copy.stemmed.str.contains('draft',na=False)\n","                                   )\n","                                   ]"],"metadata":{"id":"Awtg-PT_P83T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_draft = df_sentences_copy.loc[(df_sentences_copy.stemmed.str.contains('write manuscript',na=False) | \n","                                 df_sentences_copy.stemmed.str.contains('wrote manuscript',na=False) |\n","                                 df_sentences_copy.stemmed.str.contains('origin draft manuscript',na=False) |\n","                                 df_sentences_copy.stemmed.str.contains('write paper',na=False) |\n","                                 df_sentences_copy.stemmed.str.contains('wrote paper',na=False) |\n","                                 df_sentences_copy.stemmed.str.contains('cowrot paper',na=False) |\n","                                 df_sentences_copy.stemmed.str.contains('cowrit paper',na=False)) &\n","                                 ~(\n","                                     df_sentences_copy.stemmed.str.contains('supervis',na=False) |\n","                                   df_sentences_copy.stemmed.str.contains('design',na=False) |\n","                                   df_sentences_copy.stemmed.str.contains('All',na=False) |\n","                                   df_sentences_copy.stemmed.str.contains('analyz',na=False) \n","                                 )\n","                                 ]"],"metadata":{"id":"DCh4QFcJROp9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_review_edit_sample = df_review_edit.sample(n=100, random_state=123).drop(columns=['AuthorsId_removed', 'punctuation_stopWord_removed','stemmed'])\n","df_review_edit_sample['Label'] = 'Writing - Review and Editing'\n","df_draft_sample = df_draft.sample(n=100, random_state=123).drop(columns=['AuthorsId_removed', 'punctuation_stopWord_removed','stemmed'])\n","df_draft_sample['Label'] = 'Writing - Original Draft'"],"metadata":{"id":"l7DG8bDQNAhX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_draft_sample.to_csv('/content/drive/MyDrive/ENGI 4800/data/Writing - Original Draft.csv')\n","df_review_edit_sample.to_csv('/content/drive/MyDrive/ENGI 4800/data/Writing - Review and Editing.csv')"],"metadata":{"id":"u3ZLIWZB9oxI"},"execution_count":null,"outputs":[]}]}